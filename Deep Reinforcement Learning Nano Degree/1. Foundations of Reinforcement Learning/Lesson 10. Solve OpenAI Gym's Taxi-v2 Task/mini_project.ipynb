{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monitor import interact\n",
    "import gym\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "class Agent:\n",
    "\n",
    "    def __init__(self, nA=6, eps=0.005, alpha=1, gamma=1.0):\n",
    "        \"\"\" Initialize agent.\n",
    "\n",
    "        Params\n",
    "        ======\n",
    "        - nA: number of actions available to the agent\n",
    "        \"\"\"\n",
    "        self.nA = nA\n",
    "        self.Q = defaultdict(lambda: np.zeros(self.nA))\n",
    "        self.eps = eps\n",
    "        \n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        \n",
    "    def select_action(self, state):\n",
    "        \"\"\" Given the state, select an action.\n",
    "\n",
    "        Params\n",
    "        ======\n",
    "        - state: the current state of the environment\n",
    "\n",
    "        Returns\n",
    "        =======\n",
    "        - action: an integer, compatible with the task's action space\n",
    "        \"\"\"\n",
    "        if np.random.random() > self.eps:\n",
    "            return np.argmax(self.Q[state])\n",
    "        else:\n",
    "            return np.random.choice(self.nA)\n",
    "\n",
    "    def step(self, state, action, reward, next_state, done):\n",
    "        \"\"\" Update the agent's knowledge, using the most recently sampled tuple.\n",
    "\n",
    "        Params\n",
    "        ======\n",
    "        - state: the previous state of the environment\n",
    "        - action: the agent's previous choice of action\n",
    "        - reward: last reward received\n",
    "        - next_state: the current state of the environment\n",
    "        - done: whether the episode is complete (True or False)\n",
    "        \"\"\"\n",
    "        current = self.Q[state][action]\n",
    "        greedy_action = np.argmax(self.Q[next_state])\n",
    "        \n",
    "        policy_probs = np.ones(self.nA) * (self.eps / self.nA)\n",
    "        policy_probs[greedy_action] += (1-self.eps)\n",
    "        \n",
    "        expected_Q = sum(policy_probs * self.Q[next_state])\n",
    "        \n",
    "        self.Q[state][action] = current + (self.alpha * (reward + (self.gamma * expected_Q) - current))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('Taxi-v3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |   alpha   |    esp    |   gamma   |\n",
      "-------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 4.82    \u001b[0m | \u001b[0m 0.2021  \u001b[0m | \u001b[0m 0.09747 \u001b[0m | \u001b[0m 0.8101  \u001b[0m |\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m 6.15    \u001b[0m | \u001b[95m 0.4163  \u001b[0m | \u001b[95m 0.07105 \u001b[0m | \u001b[95m 0.8597  \u001b[0m |\n",
      "| \u001b[95m 3       \u001b[0m | \u001b[95m 7.27    \u001b[0m | \u001b[95m 0.681   \u001b[0m | \u001b[95m 0.04205 \u001b[0m | \u001b[95m 0.7942  \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 6.53    \u001b[0m | \u001b[0m 0.9757  \u001b[0m | \u001b[0m 0.05574 \u001b[0m | \u001b[0m 0.9547  \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 0.786   \u001b[0m | \u001b[0m 0.08894 \u001b[0m | \u001b[0m 0.9198  \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 4.68    \u001b[0m | \u001b[0m 0.3885  \u001b[0m | \u001b[0m 0.08556 \u001b[0m | \u001b[0m 0.6104  \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 6.98    \u001b[0m | \u001b[0m 0.9826  \u001b[0m | \u001b[0m 0.05415 \u001b[0m | \u001b[0m 0.8778  \u001b[0m |\n",
      "| \u001b[95m 8       \u001b[0m | \u001b[95m 7.75    \u001b[0m | \u001b[95m 0.6564  \u001b[0m | \u001b[95m 0.03034 \u001b[0m | \u001b[95m 0.7665  \u001b[0m |\n",
      "| \u001b[95m 9       \u001b[0m | \u001b[95m 8.92    \u001b[0m | \u001b[95m 0.6655  \u001b[0m | \u001b[95m 0.001   \u001b[0m | \u001b[95m 0.7151  \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 8.82    \u001b[0m | \u001b[0m 0.6968  \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 0.6649  \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 8.78    \u001b[0m | \u001b[0m 0.6416  \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 0.6706  \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 5.12    \u001b[0m | \u001b[0m 0.22    \u001b[0m | \u001b[0m 0.08105 \u001b[0m | \u001b[0m 0.6873  \u001b[0m |\n",
      "| \u001b[95m 13      \u001b[0m | \u001b[95m 8.96    \u001b[0m | \u001b[95m 0.9369  \u001b[0m | \u001b[95m 0.001   \u001b[0m | \u001b[95m 0.6219  \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 8.45    \u001b[0m | \u001b[0m 0.8684  \u001b[0m | \u001b[0m 0.006579\u001b[0m | \u001b[0m 0.4133  \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 8.55    \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 0.5191  \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m 8.65    \u001b[0m | \u001b[0m 0.6932  \u001b[0m | \u001b[0m 0.00198 \u001b[0m | \u001b[0m 0.672   \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 8.73    \u001b[0m | \u001b[0m 0.7296  \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 0.6037  \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m 8.66    \u001b[0m | \u001b[0m 0.907   \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 0.5503  \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 6.87    \u001b[0m | \u001b[0m 0.9639  \u001b[0m | \u001b[0m 0.0614  \u001b[0m | \u001b[0m 0.5925  \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m 8.0     \u001b[0m | \u001b[0m 0.8284  \u001b[0m | \u001b[0m 0.03259 \u001b[0m | \u001b[0m 0.6751  \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m 8.73    \u001b[0m | \u001b[0m 0.6888  \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 0.6256  \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m 8.76    \u001b[0m | \u001b[0m 0.8872  \u001b[0m | \u001b[0m 0.001475\u001b[0m | \u001b[0m 0.6136  \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m 7.99    \u001b[0m | \u001b[0m 0.4832  \u001b[0m | \u001b[0m 0.02755 \u001b[0m | \u001b[0m 0.5444  \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m 5.1     \u001b[0m | \u001b[0m 0.9162  \u001b[0m | \u001b[0m 0.09196 \u001b[0m | \u001b[0m 0.8806  \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m 8.61    \u001b[0m | \u001b[0m 0.743   \u001b[0m | \u001b[0m 0.004689\u001b[0m | \u001b[0m 0.6572  \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m 8.58    \u001b[0m | \u001b[0m 0.9651  \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 0.4343  \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m 8.59    \u001b[0m | \u001b[0m 0.9347  \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 0.6833  \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m 8.67    \u001b[0m | \u001b[0m 0.6037  \u001b[0m | \u001b[0m 0.002178\u001b[0m | \u001b[0m 0.7314  \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m 5.72    \u001b[0m | \u001b[0m 0.9821  \u001b[0m | \u001b[0m 0.0829  \u001b[0m | \u001b[0m 0.7506  \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m 7.83    \u001b[0m | \u001b[0m 0.6275  \u001b[0m | \u001b[0m 0.02853 \u001b[0m | \u001b[0m 0.73    \u001b[0m |\n",
      "| \u001b[0m 31      \u001b[0m | \u001b[0m 6.42    \u001b[0m | \u001b[0m 0.7179  \u001b[0m | \u001b[0m 0.06648 \u001b[0m | \u001b[0m 0.8857  \u001b[0m |\n",
      "| \u001b[0m 32      \u001b[0m | \u001b[0m 7.27    \u001b[0m | \u001b[0m 0.5468  \u001b[0m | \u001b[0m 0.01612 \u001b[0m | \u001b[0m 0.4578  \u001b[0m |\n",
      "| \u001b[0m 33      \u001b[0m | \u001b[0m 8.59    \u001b[0m | \u001b[0m 0.9389  \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 0.3107  \u001b[0m |\n",
      "| \u001b[0m 34      \u001b[0m | \u001b[0m-102.9   \u001b[0m | \u001b[0m 0.931   \u001b[0m | \u001b[0m 0.09445 \u001b[0m | \u001b[0m 0.3426  \u001b[0m |\n",
      "| \u001b[0m 35      \u001b[0m | \u001b[0m 8.25    \u001b[0m | \u001b[0m 0.9813  \u001b[0m | \u001b[0m 0.01309 \u001b[0m | \u001b[0m 0.8138  \u001b[0m |\n",
      "| \u001b[0m 36      \u001b[0m | \u001b[0m 8.78    \u001b[0m | \u001b[0m 0.8072  \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 0.4682  \u001b[0m |\n",
      "| \u001b[0m 37      \u001b[0m | \u001b[0m 4.8     \u001b[0m | \u001b[0m 0.3003  \u001b[0m | \u001b[0m 0.08176 \u001b[0m | \u001b[0m 0.6396  \u001b[0m |\n",
      "| \u001b[0m 38      \u001b[0m | \u001b[0m 7.87    \u001b[0m | \u001b[0m 0.4749  \u001b[0m | \u001b[0m 0.02666 \u001b[0m | \u001b[0m 0.7454  \u001b[0m |\n",
      "| \u001b[0m 39      \u001b[0m | \u001b[0m 8.61    \u001b[0m | \u001b[0m 0.378   \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 0.3921  \u001b[0m |\n",
      "| \u001b[0m 40      \u001b[0m | \u001b[0m-93.14   \u001b[0m | \u001b[0m 0.4473  \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.3005  \u001b[0m |\n",
      "| \u001b[0m 41      \u001b[0m | \u001b[0m 8.89    \u001b[0m | \u001b[0m 0.3317  \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 0.4643  \u001b[0m |\n",
      "| \u001b[0m 42      \u001b[0m | \u001b[0m 8.77    \u001b[0m | \u001b[0m 0.559   \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "| \u001b[0m 43      \u001b[0m | \u001b[0m 4.92    \u001b[0m | \u001b[0m 0.2515  \u001b[0m | \u001b[0m 0.06654 \u001b[0m | \u001b[0m 0.6028  \u001b[0m |\n",
      "| \u001b[0m 44      \u001b[0m | \u001b[0m 8.59    \u001b[0m | \u001b[0m 0.2944  \u001b[0m | \u001b[0m 0.001672\u001b[0m | \u001b[0m 0.9844  \u001b[0m |\n",
      "| \u001b[0m 45      \u001b[0m | \u001b[0m 8.38    \u001b[0m | \u001b[0m 0.1064  \u001b[0m | \u001b[0m 0.01321 \u001b[0m | \u001b[0m 0.9871  \u001b[0m |\n",
      "| \u001b[0m 46      \u001b[0m | \u001b[0m 8.38    \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 0.3988  \u001b[0m |\n",
      "| \u001b[0m 47      \u001b[0m | \u001b[0m 5.27    \u001b[0m | \u001b[0m 0.4166  \u001b[0m | \u001b[0m 0.09226 \u001b[0m | \u001b[0m 0.9976  \u001b[0m |\n",
      "| \u001b[0m 48      \u001b[0m | \u001b[0m 5.02    \u001b[0m | \u001b[0m 0.2058  \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "| \u001b[0m 49      \u001b[0m | \u001b[0m 3.46    \u001b[0m | \u001b[0m 0.1189  \u001b[0m | \u001b[0m 0.08005 \u001b[0m | \u001b[0m 0.6582  \u001b[0m |\n",
      "| \u001b[0m 50      \u001b[0m | \u001b[0m 8.6     \u001b[0m | \u001b[0m 0.5929  \u001b[0m | \u001b[0m 0.002781\u001b[0m | \u001b[0m 0.5179  \u001b[0m |\n",
      "| \u001b[0m 51      \u001b[0m | \u001b[0m 8.29    \u001b[0m | \u001b[0m 0.8402  \u001b[0m | \u001b[0m 0.01915 \u001b[0m | \u001b[0m 0.5006  \u001b[0m |\n",
      "| \u001b[0m 52      \u001b[0m | \u001b[0m-16.51   \u001b[0m | \u001b[0m 0.4584  \u001b[0m | \u001b[0m 0.07317 \u001b[0m | \u001b[0m 0.4046  \u001b[0m |\n",
      "| \u001b[0m 53      \u001b[0m | \u001b[0m 8.44    \u001b[0m | \u001b[0m 0.419   \u001b[0m | \u001b[0m 0.00426 \u001b[0m | \u001b[0m 0.4541  \u001b[0m |\n",
      "=============================================================\n",
      "{'target': 8.96, 'params': {'alpha': 0.9369173106474218, 'esp': 0.001, 'gamma': 0.6218822154541953}}\n"
     ]
    }
   ],
   "source": [
    "# https://wooono.tistory.com/102\n",
    "\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "# Set of hyperparemeters\n",
    "pbounds = {'eps': (0.001, 0.1),\n",
    "            'alpha': (0.1, 1),\n",
    "            'gamma': (0.3, 1),\n",
    "            }\n",
    "\n",
    "# Function to optimize\n",
    "def opt_function(eps, alpha, gamma):\n",
    "    agent = Agent(eps=eps, alpha=alpha, gamma=gamma)\n",
    "    _, best_avg_reward = interact(env, agent, verbose=False)\n",
    "    \n",
    "    return best_avg_reward\n",
    "\n",
    "# Bayesian optimization Object\n",
    "# f : Target Function, pbounds : hyperparameter set\n",
    "# verbose = 2 Print always, verbose = 1 Print when find maximum, verbose = 0 No Print\n",
    "# random_state : Seed\n",
    "bo=BayesianOptimization(f=opt_function, pbounds=pbounds, verbose=2, random_state=47)    \n",
    "\n",
    "# Run target value maximize\n",
    "# init_points :  Initial Random Search Counts\n",
    "# n_iter : The number of Iteration\n",
    "# acq : Acquisition Functions - Expected Improvement(EI), Probability of Improvement(PI), Upper Confidence Bound(UCB)\n",
    "# xi : Exploration Strength\n",
    "bo.maximize(init_points=3, n_iter=50, acq='ei', xi=0.01)\n",
    "\n",
    "print(bo.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "class Agent2:\n",
    "\n",
    "    def __init__(self, nA=6, eps=0.005, eps_decay=0.9, alpha=1, gamma=1.0):\n",
    "        \"\"\" Initialize agent.\n",
    "\n",
    "        Params\n",
    "        ======\n",
    "        - nA: number of actions available to the agent\n",
    "        \"\"\"\n",
    "        self.nA = nA\n",
    "        self.Q = defaultdict(lambda: np.zeros(self.nA))\n",
    "        self.eps = eps\n",
    "        self.eps_decay = eps_decay\n",
    "        \n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        \n",
    "    def get_policy_probs(self, state):\n",
    "        greedy_action = np.argmax(self.Q[state])        \n",
    "        policy_probs = np.ones(self.nA) * (self.eps / self.nA)\n",
    "        policy_probs[greedy_action] += (1-self.eps)\n",
    "        \n",
    "        return policy_probs\n",
    "        \n",
    "    def select_action(self, state):\n",
    "        \"\"\" Given the state, select an action.\n",
    "\n",
    "        Params\n",
    "        ======\n",
    "        - state: the current state of the environment\n",
    "\n",
    "        Returns\n",
    "        =======\n",
    "        - action: an integer, compatible with the task's action space\n",
    "        \"\"\"\n",
    "        return np.random.choice(self.nA, p=self.get_policy_probs(state))\n",
    "\n",
    "    def step(self, state, action, reward, next_state, done):\n",
    "        \"\"\" Update the agent's knowledge, using the most recently sampled tuple.\n",
    "\n",
    "        Params\n",
    "        ======\n",
    "        - state: the previous state of the environment\n",
    "        - action: the agent's previous choice of action\n",
    "        - reward: last reward received\n",
    "        - next_state: the current state of the environment\n",
    "        - done: whether the episode is complete (True or False)\n",
    "        \"\"\"\n",
    "        current = self.Q[state][action]\n",
    "        policy_probs = self.get_policy_probs(next_state)\n",
    "        expected_Q = sum(policy_probs * self.Q[next_state])\n",
    "        \n",
    "        self.Q[state][action] = current + (self.alpha * (reward + (self.gamma * expected_Q) - current))\n",
    "        \n",
    "        if done:\n",
    "            self.eps = self.eps * self.eps_decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |   alpha   |    eps    | eps_decay |   gamma   |\n",
      "-------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 9.11    \u001b[0m | \u001b[0m 0.2021  \u001b[0m | \u001b[0m 0.09747 \u001b[0m | \u001b[0m 0.683   \u001b[0m | \u001b[0m 0.546   \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m 8.54    \u001b[0m | \u001b[0m 0.7368  \u001b[0m | \u001b[0m 0.08016 \u001b[0m | \u001b[0m 0.6164  \u001b[0m | \u001b[0m 0.5902  \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 8.73    \u001b[0m | \u001b[0m 0.7354  \u001b[0m | \u001b[0m 0.02542 \u001b[0m | \u001b[0m 0.3048  \u001b[0m | \u001b[0m 0.3168  \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 9.0     \u001b[0m | \u001b[0m 0.215   \u001b[0m | \u001b[0m 0.09028 \u001b[0m | \u001b[0m 0.6996  \u001b[0m | \u001b[0m 0.5469  \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 8.73    \u001b[0m | \u001b[0m 0.2044  \u001b[0m | \u001b[0m 0.09766 \u001b[0m | \u001b[0m 0.6244  \u001b[0m | \u001b[0m 0.5422  \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 8.83    \u001b[0m | \u001b[0m 0.2266  \u001b[0m | \u001b[0m 0.07713 \u001b[0m | \u001b[0m 0.7246  \u001b[0m | \u001b[0m 0.5572  \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 8.7     \u001b[0m | \u001b[0m 0.1849  \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.6913  \u001b[0m | \u001b[0m 0.5427  \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 8.89    \u001b[0m | \u001b[0m 0.7373  \u001b[0m | \u001b[0m 0.08983 \u001b[0m | \u001b[0m 0.8958  \u001b[0m | \u001b[0m 0.7685  \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 8.7     \u001b[0m | \u001b[0m 0.4025  \u001b[0m | \u001b[0m 0.01256 \u001b[0m | \u001b[0m 0.3243  \u001b[0m | \u001b[0m 0.6511  \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 8.9     \u001b[0m | \u001b[0m 0.9292  \u001b[0m | \u001b[0m 0.03196 \u001b[0m | \u001b[0m 0.1758  \u001b[0m | \u001b[0m 0.3413  \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 8.85    \u001b[0m | \u001b[0m 0.5644  \u001b[0m | \u001b[0m 0.01335 \u001b[0m | \u001b[0m 0.3704  \u001b[0m | \u001b[0m 0.6178  \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 8.78    \u001b[0m | \u001b[0m 0.831   \u001b[0m | \u001b[0m 0.002704\u001b[0m | \u001b[0m 0.5649  \u001b[0m | \u001b[0m 0.5523  \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 8.86    \u001b[0m | \u001b[0m 0.364   \u001b[0m | \u001b[0m 0.05828 \u001b[0m | \u001b[0m 0.4333  \u001b[0m | \u001b[0m 0.6621  \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 8.79    \u001b[0m | \u001b[0m 0.2704  \u001b[0m | \u001b[0m 0.01866 \u001b[0m | \u001b[0m 0.3718  \u001b[0m | \u001b[0m 0.4674  \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 8.74    \u001b[0m | \u001b[0m 0.2787  \u001b[0m | \u001b[0m 0.08152 \u001b[0m | \u001b[0m 0.6427  \u001b[0m | \u001b[0m 0.5339  \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m 8.72    \u001b[0m | \u001b[0m 0.7556  \u001b[0m | \u001b[0m 0.0145  \u001b[0m | \u001b[0m 0.5364  \u001b[0m | \u001b[0m 0.3616  \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 8.81    \u001b[0m | \u001b[0m 0.1876  \u001b[0m | \u001b[0m 0.02992 \u001b[0m | \u001b[0m 0.4628  \u001b[0m | \u001b[0m 0.6096  \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m 8.95    \u001b[0m | \u001b[0m 0.2646  \u001b[0m | \u001b[0m 0.06643 \u001b[0m | \u001b[0m 0.8011  \u001b[0m | \u001b[0m 0.9671  \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 8.89    \u001b[0m | \u001b[0m 0.948   \u001b[0m | \u001b[0m 0.001044\u001b[0m | \u001b[0m 0.4181  \u001b[0m | \u001b[0m 0.6341  \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m 8.99    \u001b[0m | \u001b[0m 0.6401  \u001b[0m | \u001b[0m 0.0829  \u001b[0m | \u001b[0m 0.1463  \u001b[0m | \u001b[0m 0.9276  \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m 8.74    \u001b[0m | \u001b[0m 0.2135  \u001b[0m | \u001b[0m 0.01068 \u001b[0m | \u001b[0m 0.8968  \u001b[0m | \u001b[0m 0.5458  \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m 8.59    \u001b[0m | \u001b[0m 0.8499  \u001b[0m | \u001b[0m 0.01371 \u001b[0m | \u001b[0m 0.536   \u001b[0m | \u001b[0m 0.6386  \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m 8.82    \u001b[0m | \u001b[0m 0.7398  \u001b[0m | \u001b[0m 0.0616  \u001b[0m | \u001b[0m 0.4803  \u001b[0m | \u001b[0m 0.3613  \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m 8.76    \u001b[0m | \u001b[0m 0.6882  \u001b[0m | \u001b[0m 0.04095 \u001b[0m | \u001b[0m 0.87    \u001b[0m | \u001b[0m 0.8746  \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m 8.69    \u001b[0m | \u001b[0m 0.1525  \u001b[0m | \u001b[0m 0.06029 \u001b[0m | \u001b[0m 0.4442  \u001b[0m | \u001b[0m 0.909   \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m 8.76    \u001b[0m | \u001b[0m 0.9539  \u001b[0m | \u001b[0m 0.04477 \u001b[0m | \u001b[0m 0.4348  \u001b[0m | \u001b[0m 0.3163  \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m 8.76    \u001b[0m | \u001b[0m 0.2215  \u001b[0m | \u001b[0m 0.02405 \u001b[0m | \u001b[0m 0.6051  \u001b[0m | \u001b[0m 0.5121  \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m 8.63    \u001b[0m | \u001b[0m 0.973   \u001b[0m | \u001b[0m 0.08146 \u001b[0m | \u001b[0m 0.8464  \u001b[0m | \u001b[0m 0.8057  \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m 8.77    \u001b[0m | \u001b[0m 0.6135  \u001b[0m | \u001b[0m 0.02684 \u001b[0m | \u001b[0m 0.4831  \u001b[0m | \u001b[0m 0.5478  \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m 8.93    \u001b[0m | \u001b[0m 0.208   \u001b[0m | \u001b[0m 0.07972 \u001b[0m | \u001b[0m 0.6891  \u001b[0m | \u001b[0m 0.5293  \u001b[0m |\n",
      "| \u001b[0m 31      \u001b[0m | \u001b[0m 8.69    \u001b[0m | \u001b[0m 0.2349  \u001b[0m | \u001b[0m 0.07202 \u001b[0m | \u001b[0m 0.812   \u001b[0m | \u001b[0m 0.4381  \u001b[0m |\n",
      "| \u001b[0m 32      \u001b[0m | \u001b[0m 8.69    \u001b[0m | \u001b[0m 0.9747  \u001b[0m | \u001b[0m 0.0868  \u001b[0m | \u001b[0m 0.5926  \u001b[0m | \u001b[0m 0.5887  \u001b[0m |\n",
      "| \u001b[0m 33      \u001b[0m | \u001b[0m 8.77    \u001b[0m | \u001b[0m 0.6882  \u001b[0m | \u001b[0m 0.003917\u001b[0m | \u001b[0m 0.7271  \u001b[0m | \u001b[0m 0.4401  \u001b[0m |\n",
      "=========================================================================\n",
      "{'target': 9.11, 'params': {'alpha': 0.2021396247042846, 'eps': 0.09747382634920922, 'eps_decay': 0.6829877068008849, 'gamma': 0.546027464124891}}\n"
     ]
    }
   ],
   "source": [
    "pbounds2 = {'eps': (0.001, 0.1),\n",
    "            'eps_decay': (0.1, 0.9),\n",
    "            'alpha': (0.1, 1),\n",
    "            'gamma': (0.3, 1),\n",
    "            }\n",
    "\n",
    "def opt_function2(eps, eps_decay, alpha, gamma):\n",
    "    agent = Agent2(eps=eps, eps_decay=eps_decay, alpha=alpha, gamma=gamma)\n",
    "    _, best_avg_reward = interact(env, agent, verbose=False)\n",
    "    \n",
    "    return best_avg_reward\n",
    "\n",
    "bo2 = BayesianOptimization(f=opt_function2, pbounds=pbounds2, verbose=2, random_state=47)    \n",
    "bo2.maximize(init_points=3, n_iter=30, acq='ei', xi=0.01)\n",
    "print(bo2.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |   alpha   |    eps    |   gamma   |\n",
      "-------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 5.74    \u001b[0m | \u001b[0m 0.2021  \u001b[0m | \u001b[0m 0.09747 \u001b[0m | \u001b[0m 0.8101  \u001b[0m |\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m 6.36    \u001b[0m | \u001b[95m 0.4163  \u001b[0m | \u001b[95m 0.07105 \u001b[0m | \u001b[95m 0.8597  \u001b[0m |\n",
      "| \u001b[95m 3       \u001b[0m | \u001b[95m 7.17    \u001b[0m | \u001b[95m 0.681   \u001b[0m | \u001b[95m 0.04205 \u001b[0m | \u001b[95m 0.7942  \u001b[0m |\n",
      "| \u001b[95m 4       \u001b[0m | \u001b[95m 8.19    \u001b[0m | \u001b[95m 0.6665  \u001b[0m | \u001b[95m 0.01628 \u001b[0m | \u001b[95m 0.7712  \u001b[0m |\n",
      "| \u001b[95m 5       \u001b[0m | \u001b[95m 8.38    \u001b[0m | \u001b[95m 0.6456  \u001b[0m | \u001b[95m 0.01384 \u001b[0m | \u001b[95m 0.7457  \u001b[0m |\n",
      "| \u001b[95m 6       \u001b[0m | \u001b[95m 8.71    \u001b[0m | \u001b[95m 0.7053  \u001b[0m | \u001b[95m 0.001   \u001b[0m | \u001b[95m 0.7016  \u001b[0m |\n",
      "| \u001b[95m 7       \u001b[0m | \u001b[95m 9.12    \u001b[0m | \u001b[95m 0.6711  \u001b[0m | \u001b[95m 0.001   \u001b[0m | \u001b[95m 0.5987  \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 8.58    \u001b[0m | \u001b[0m 0.7774  \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 0.5595  \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 8.8     \u001b[0m | \u001b[0m 0.6373  \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 0.4742  \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-3.8     \u001b[0m | \u001b[0m 0.6725  \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.5374  \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m-109.2   \u001b[0m | \u001b[0m 0.8627  \u001b[0m | \u001b[0m 0.09445 \u001b[0m | \u001b[0m 0.398   \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 8.55    \u001b[0m | \u001b[0m 0.667   \u001b[0m | \u001b[0m 0.004676\u001b[0m | \u001b[0m 0.6026  \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 8.54    \u001b[0m | \u001b[0m 0.2931  \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 0.4265  \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 8.53    \u001b[0m | \u001b[0m 0.8684  \u001b[0m | \u001b[0m 0.006579\u001b[0m | \u001b[0m 0.4133  \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 8.75    \u001b[0m | \u001b[0m 0.837   \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 0.6756  \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m 5.21    \u001b[0m | \u001b[0m 0.7709  \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.6885  \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 8.85    \u001b[0m | \u001b[0m 0.8094  \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 0.7974  \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m 5.62    \u001b[0m | \u001b[0m 0.8986  \u001b[0m | \u001b[0m 0.08343 \u001b[0m | \u001b[0m 0.7679  \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 4.64    \u001b[0m | \u001b[0m 0.7964  \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.8662  \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m 7.67    \u001b[0m | \u001b[0m 0.8284  \u001b[0m | \u001b[0m 0.03259 \u001b[0m | \u001b[0m 0.6751  \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m 8.66    \u001b[0m | \u001b[0m 0.4366  \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 0.4475  \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m 8.84    \u001b[0m | \u001b[0m 0.5221  \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 0.5475  \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m 7.02    \u001b[0m | \u001b[0m 0.4832  \u001b[0m | \u001b[0m 0.02755 \u001b[0m | \u001b[0m 0.5444  \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m 5.4     \u001b[0m | \u001b[0m 0.9162  \u001b[0m | \u001b[0m 0.09196 \u001b[0m | \u001b[0m 0.8806  \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m 8.17    \u001b[0m | \u001b[0m 0.5469  \u001b[0m | \u001b[0m 0.003728\u001b[0m | \u001b[0m 0.3631  \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m 7.35    \u001b[0m | \u001b[0m 0.3934  \u001b[0m | \u001b[0m 0.004892\u001b[0m | \u001b[0m 0.3192  \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m 4.78    \u001b[0m | \u001b[0m 0.212   \u001b[0m | \u001b[0m 0.05386 \u001b[0m | \u001b[0m 0.5518  \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m-22.9    \u001b[0m | \u001b[0m 0.3754  \u001b[0m | \u001b[0m 0.09681 \u001b[0m | \u001b[0m 0.4058  \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m 5.8     \u001b[0m | \u001b[0m 0.9821  \u001b[0m | \u001b[0m 0.0829  \u001b[0m | \u001b[0m 0.7506  \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m 7.84    \u001b[0m | \u001b[0m 0.6275  \u001b[0m | \u001b[0m 0.02853 \u001b[0m | \u001b[0m 0.73    \u001b[0m |\n",
      "| \u001b[0m 31      \u001b[0m | \u001b[0m 6.36    \u001b[0m | \u001b[0m 0.7179  \u001b[0m | \u001b[0m 0.06648 \u001b[0m | \u001b[0m 0.8857  \u001b[0m |\n",
      "| \u001b[0m 32      \u001b[0m | \u001b[0m 8.62    \u001b[0m | \u001b[0m 0.1625  \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 0.3997  \u001b[0m |\n",
      "| \u001b[0m 33      \u001b[0m | \u001b[0m 8.48    \u001b[0m | \u001b[0m 0.2429  \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 0.3     \u001b[0m |\n",
      "=============================================================\n",
      "{'target': 9.12, 'params': {'alpha': 0.6711067485464264, 'eps': 0.001, 'gamma': 0.5986902759712246}}\n"
     ]
    }
   ],
   "source": [
    "bo3=BayesianOptimization(f=opt_function, pbounds=pbounds, verbose=2, random_state=47)    \n",
    "bo3.maximize(init_points=3, n_iter=30)\n",
    "print(bo3.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |   alpha   |    eps    | eps_decay |   gamma   |\n",
      "-------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 8.93    \u001b[0m | \u001b[0m 0.2021  \u001b[0m | \u001b[0m 0.09747 \u001b[0m | \u001b[0m 0.683   \u001b[0m | \u001b[0m 0.546   \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m 8.73    \u001b[0m | \u001b[0m 0.7368  \u001b[0m | \u001b[0m 0.08016 \u001b[0m | \u001b[0m 0.6164  \u001b[0m | \u001b[0m 0.5902  \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 8.74    \u001b[0m | \u001b[0m 0.7354  \u001b[0m | \u001b[0m 0.02542 \u001b[0m | \u001b[0m 0.3048  \u001b[0m | \u001b[0m 0.3168  \u001b[0m |\n",
      "| \u001b[95m 4       \u001b[0m | \u001b[95m 8.99    \u001b[0m | \u001b[95m 0.1997  \u001b[0m | \u001b[95m 0.07971 \u001b[0m | \u001b[95m 0.6642  \u001b[0m | \u001b[95m 0.5726  \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 8.83    \u001b[0m | \u001b[0m 0.2069  \u001b[0m | \u001b[0m 0.09399 \u001b[0m | \u001b[0m 0.6782  \u001b[0m | \u001b[0m 0.5194  \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 8.73    \u001b[0m | \u001b[0m 0.1781  \u001b[0m | \u001b[0m 0.06616 \u001b[0m | \u001b[0m 0.8858  \u001b[0m | \u001b[0m 0.9891  \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 8.84    \u001b[0m | \u001b[0m 0.1914  \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.6936  \u001b[0m | \u001b[0m 0.606   \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 8.78    \u001b[0m | \u001b[0m 0.2213  \u001b[0m | \u001b[0m 0.08022 \u001b[0m | \u001b[0m 0.619   \u001b[0m | \u001b[0m 0.5732  \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 8.73    \u001b[0m | \u001b[0m 0.1918  \u001b[0m | \u001b[0m 0.08865 \u001b[0m | \u001b[0m 0.6577  \u001b[0m | \u001b[0m 0.5579  \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 8.75    \u001b[0m | \u001b[0m 0.9292  \u001b[0m | \u001b[0m 0.03196 \u001b[0m | \u001b[0m 0.1758  \u001b[0m | \u001b[0m 0.3413  \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 8.89    \u001b[0m | \u001b[0m 0.5644  \u001b[0m | \u001b[0m 0.01335 \u001b[0m | \u001b[0m 0.3704  \u001b[0m | \u001b[0m 0.6178  \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 8.85    \u001b[0m | \u001b[0m 0.831   \u001b[0m | \u001b[0m 0.002704\u001b[0m | \u001b[0m 0.5649  \u001b[0m | \u001b[0m 0.5523  \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 8.88    \u001b[0m | \u001b[0m 0.364   \u001b[0m | \u001b[0m 0.05828 \u001b[0m | \u001b[0m 0.4333  \u001b[0m | \u001b[0m 0.6621  \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 8.72    \u001b[0m | \u001b[0m 0.2704  \u001b[0m | \u001b[0m 0.01866 \u001b[0m | \u001b[0m 0.3718  \u001b[0m | \u001b[0m 0.4674  \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 8.64    \u001b[0m | \u001b[0m 0.2787  \u001b[0m | \u001b[0m 0.08152 \u001b[0m | \u001b[0m 0.6427  \u001b[0m | \u001b[0m 0.5339  \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m 8.75    \u001b[0m | \u001b[0m 0.7556  \u001b[0m | \u001b[0m 0.0145  \u001b[0m | \u001b[0m 0.5364  \u001b[0m | \u001b[0m 0.3616  \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 8.8     \u001b[0m | \u001b[0m 0.1876  \u001b[0m | \u001b[0m 0.02992 \u001b[0m | \u001b[0m 0.4628  \u001b[0m | \u001b[0m 0.6096  \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m 8.79    \u001b[0m | \u001b[0m 0.2646  \u001b[0m | \u001b[0m 0.06643 \u001b[0m | \u001b[0m 0.8011  \u001b[0m | \u001b[0m 0.9671  \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 8.71    \u001b[0m | \u001b[0m 0.948   \u001b[0m | \u001b[0m 0.001044\u001b[0m | \u001b[0m 0.4181  \u001b[0m | \u001b[0m 0.6341  \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m 8.74    \u001b[0m | \u001b[0m 0.6401  \u001b[0m | \u001b[0m 0.0829  \u001b[0m | \u001b[0m 0.1463  \u001b[0m | \u001b[0m 0.9276  \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m 8.94    \u001b[0m | \u001b[0m 0.2135  \u001b[0m | \u001b[0m 0.01068 \u001b[0m | \u001b[0m 0.8968  \u001b[0m | \u001b[0m 0.5458  \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m 8.55    \u001b[0m | \u001b[0m 0.8499  \u001b[0m | \u001b[0m 0.01371 \u001b[0m | \u001b[0m 0.536   \u001b[0m | \u001b[0m 0.6386  \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m 8.77    \u001b[0m | \u001b[0m 0.7398  \u001b[0m | \u001b[0m 0.0616  \u001b[0m | \u001b[0m 0.4803  \u001b[0m | \u001b[0m 0.3613  \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m 8.77    \u001b[0m | \u001b[0m 0.6882  \u001b[0m | \u001b[0m 0.04095 \u001b[0m | \u001b[0m 0.87    \u001b[0m | \u001b[0m 0.8746  \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m 8.82    \u001b[0m | \u001b[0m 0.1525  \u001b[0m | \u001b[0m 0.06029 \u001b[0m | \u001b[0m 0.4442  \u001b[0m | \u001b[0m 0.909   \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m 8.97    \u001b[0m | \u001b[0m 0.9539  \u001b[0m | \u001b[0m 0.04477 \u001b[0m | \u001b[0m 0.4348  \u001b[0m | \u001b[0m 0.3163  \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m 8.86    \u001b[0m | \u001b[0m 0.2215  \u001b[0m | \u001b[0m 0.02405 \u001b[0m | \u001b[0m 0.6051  \u001b[0m | \u001b[0m 0.5121  \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m 8.82    \u001b[0m | \u001b[0m 0.973   \u001b[0m | \u001b[0m 0.08146 \u001b[0m | \u001b[0m 0.8464  \u001b[0m | \u001b[0m 0.8057  \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m 8.73    \u001b[0m | \u001b[0m 0.6135  \u001b[0m | \u001b[0m 0.02684 \u001b[0m | \u001b[0m 0.4831  \u001b[0m | \u001b[0m 0.5478  \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m 8.78    \u001b[0m | \u001b[0m 0.5262  \u001b[0m | \u001b[0m 0.09955 \u001b[0m | \u001b[0m 0.4835  \u001b[0m | \u001b[0m 0.305   \u001b[0m |\n",
      "| \u001b[0m 31      \u001b[0m | \u001b[0m 8.73    \u001b[0m | \u001b[0m 0.2349  \u001b[0m | \u001b[0m 0.07202 \u001b[0m | \u001b[0m 0.812   \u001b[0m | \u001b[0m 0.4381  \u001b[0m |\n",
      "| \u001b[0m 32      \u001b[0m | \u001b[0m 8.55    \u001b[0m | \u001b[0m 0.9747  \u001b[0m | \u001b[0m 0.0868  \u001b[0m | \u001b[0m 0.5926  \u001b[0m | \u001b[0m 0.5887  \u001b[0m |\n",
      "| \u001b[95m 33      \u001b[0m | \u001b[95m 9.02    \u001b[0m | \u001b[95m 0.6882  \u001b[0m | \u001b[95m 0.003917\u001b[0m | \u001b[95m 0.7271  \u001b[0m | \u001b[95m 0.4401  \u001b[0m |\n",
      "=========================================================================\n",
      "{'target': 9.02, 'params': {'alpha': 0.6882277391906468, 'eps': 0.00391727171050456, 'eps_decay': 0.7270670581345042, 'gamma': 0.4400758344941134}}\n"
     ]
    }
   ],
   "source": [
    "bo4 = BayesianOptimization(f=opt_function2, pbounds=pbounds2, verbose=2, random_state=47)    \n",
    "bo4.maximize(init_points=3, n_iter=30)\n",
    "print(bo4.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deep Reinforcement Learning",
   "language": "python",
   "name": "rl_nano"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
