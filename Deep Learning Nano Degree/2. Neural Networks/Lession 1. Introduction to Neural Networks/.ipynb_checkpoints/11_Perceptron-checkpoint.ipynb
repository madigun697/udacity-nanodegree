{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the random seed, feel free to change it and see different solutions.\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stepFunction(t):\n",
    "    if t >= 0:\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(X, W, b):\n",
    "    return stepFunction((np.matmul(X,W)+b)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Fill in the code below to implement the perceptron trick.\n",
    "# The function should receive as inputs the data X, the labels y,\n",
    "# the weights W (as an array), and the bias b,\n",
    "# update the weights and bias W, b, according to the perceptron algorithm,\n",
    "# and return W and b.\n",
    "def perceptronStep(X, y, W, b, learn_rate = 0.01):\n",
    "    # Fill in code\n",
    "    for i in range(X.shape[0]):\n",
    "        y_hat = prediction(X[i], W, b)\n",
    "        if y_hat != y[i] and y_hat == 0:\n",
    "            W += (X[i] * learn_rate).reshape(W.shape)\n",
    "            b += learn_rate\n",
    "        elif y_hat != y[i] and y_hat == 1:\n",
    "            W -= (X[i] * learn_rate).reshape(W.shape)\n",
    "            b -= learn_rate\n",
    "    return W, b    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function runs the perceptron algorithm repeatedly on the dataset,\n",
    "# and returns a few of the boundary lines obtained in the iterations,\n",
    "# for plotting purposes.\n",
    "# Feel free to play with the learning rate and the num_epochs,\n",
    "# and see your results plotted below.\n",
    "def trainPerceptronAlgorithm(X, y, learn_rate = 0.01, num_epochs = 25):\n",
    "    x_min, x_max = min(X.T[0]), max(X.T[0])\n",
    "    y_min, y_max = min(X.T[1]), max(X.T[1])\n",
    "    W = np.array(np.random.rand(2,1))\n",
    "    b = np.random.rand(1)[0] + x_max\n",
    "    # These are the solution lines that get plotted below.\n",
    "    boundary_lines = []\n",
    "    for i in range(num_epochs):\n",
    "        # In each epoch, we apply the perceptron step.\n",
    "        W, b = perceptronStep(X, y, W, b, learn_rate)\n",
    "        boundary_lines.append((-W[0]/W[1], -b/W[1]))\n",
    "    return boundary_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('11_data.csv', names=['x1', 'x2', 'y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.77029</td>\n",
       "      <td>0.70140</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.73156</td>\n",
       "      <td>0.71782</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.44556</td>\n",
       "      <td>0.57991</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.85275</td>\n",
       "      <td>0.85987</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.51912</td>\n",
       "      <td>0.62359</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         x1       x2  y\n",
       "95  0.77029  0.70140  0\n",
       "96  0.73156  0.71782  0\n",
       "97  0.44556  0.57991  0\n",
       "98  0.85275  0.85987  0\n",
       "99  0.51912  0.62359  0"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([3.5679513]), array([4.97079108])),\n",
       " (array([0.3425572]), array([0.42998433])),\n",
       " (array([0.24930367]), array([0.33090314])),\n",
       " (array([0.20269105]), array([0.35539945])),\n",
       " (array([0.1693971]), array([0.38177774])),\n",
       " (array([0.12333581]), array([0.38388612])),\n",
       " (array([0.09695899]), array([0.41300582])),\n",
       " (array([0.05955739]), array([0.41742306])),\n",
       " (array([0.03447816]), array([0.44843148])),\n",
       " (array([0.00483292]), array([0.45383676])),\n",
       " (array([-0.02553571]), array([0.45937393])),\n",
       " (array([-0.05117847]), array([0.46397324])),\n",
       " (array([-0.06851791]), array([0.49903297])),\n",
       " (array([-0.09485408]), array([0.50563539])),\n",
       " (array([-0.12189648]), array([0.51241485])),\n",
       " (array([-0.14967388]), array([0.51937859])),\n",
       " (array([-0.17821668]), array([0.5265342])),\n",
       " (array([-0.19952008]), array([0.5322499])),\n",
       " (array([-0.22129106]), array([0.53809104])),\n",
       " (array([-0.23412324]), array([0.57779364])),\n",
       " (array([-0.25643702]), array([0.58577517])),\n",
       " (array([-0.27937592]), array([0.5939803])),\n",
       " (array([-0.30083263]), array([0.60421764])),\n",
       " (array([-0.32304194]), array([0.61481406])),\n",
       " (array([-0.34604413]), array([0.62578877]))]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainPerceptronAlgorithm(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL Nano Degree",
   "language": "python",
   "name": "ml_nano"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
